{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import IPython\n",
    "import IPython.display as ipd  # To play sound in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAMPLE_RATE = 44100\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_norm(data):\n",
    "    max_data = np.max(np.absolute(data),axis=1)\n",
    "    return data/(max_data+1e-6)*0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wav, sampling_rate = librosa.core.load('../input/audio_train/'+train.fname[0], sr=16000)\n",
    "wav = audio_norm(wav)\n",
    "IPython.display.display(ipd.Audio('../input/audio_train/'+train.fname[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.plot(wav, '-', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sampling_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#pitch shift\n",
    "bpo = 24 #how many steps per octave\n",
    "pr = 1 #pitch shift range\n",
    "ps = int(np.random.uniform(-pr * bpo, pr * bpo) + 0.5) #how many (fractional) half-steps to shift y\n",
    "shifted_wav = librosa.effects.pitch_shift(wav, sampling_rate, n_steps = ps, bins_per_octave = bpo)\n",
    "librosa.output.write_wav('../temp/temp.wav', shifted_wav, sampling_rate)\n",
    "IPython.display.display(ipd.Audio( '../temp/temp.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#time stretch\n",
    "tr = 2.0 #speed up/down rate\n",
    "lgtr = np.log(tr)\n",
    "ts = 2 ** np.random.uniform(-lgtr,lgtr)\n",
    "shifted_wav = librosa.effects.time_stretch(wav, ts)\n",
    "librosa.output.write_wav('../temp/temp.wav', shifted_wav, sampling_rate)\n",
    "IPython.display.display(ipd.Audio( '../temp/temp.wav'))\n",
    "shifted_wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# white noise\n",
    "wnvr = 0.1 # white noise volume range\n",
    "wnv  = np.random.uniform(0, wnvr) # white noise volume, random\n",
    "shifted_wav = wav + np.random.uniform(-wnv, wnv, wav.shape)\n",
    "librosa.output.write_wav('../temp/temp.wav', shifted_wav, sampling_rate)\n",
    "IPython.display.display(ipd.Audio( '../temp/temp.wav'))\n",
    "print(shifted_wav.shape)\n",
    "print(wav.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self,\n",
    "                 sampling_rate=16000, audio_duration=2, n_classes=41,\n",
    "                 use_mfcc=False, n_folds=10, learning_rate=0.0001, \n",
    "                 max_epochs=50, n_mfcc=40, datagen_num = 2):\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.audio_duration = audio_duration\n",
    "        self.n_classes = n_classes\n",
    "        self.use_mfcc = use_mfcc\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.n_folds = n_folds\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_epochs = max_epochs\n",
    "        self.datagen_num = datagen_num\n",
    "\n",
    "        self.audio_length = self.sampling_rate * self.audio_duration\n",
    "        if self.use_mfcc:\n",
    "            self.dim = (self.n_mfcc, 1 + int(np.floor(self.audio_length/512)), 1)\n",
    "        else:\n",
    "            self.dim = (self.audio_length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, config, data_dir):\n",
    "    X = np.empty(shape=(df.shape[0] * config.datagen_num, config.dim[0], config.dim[1], 1))\n",
    "    y = np.empty(df.shape[0] * config.datagen_num)\n",
    "    input_length = config.audio_length\n",
    "    for i, fname in enumerate(df.index):\n",
    "        print(fname)\n",
    "        file_path = data_dir + fname\n",
    "        data, _ = librosa.core.load(file_path, sr=config.sampling_rate)\n",
    "        data = audio_norm(data)\n",
    "        for j in range(config.datagen_num):\n",
    "            #pitch shift\n",
    "            bpo = 24 #how many steps per octave\n",
    "            pr = 1 #pitch shift range\n",
    "            ps = int(np.random.uniform(-pr * bpo, pr * bpo) + 0.5) #how many (fractional) half-steps to shift y\n",
    "            shifted_data = librosa.effects.pitch_shift(data, config.sampling_rate, n_steps = ps, bins_per_octave = bpo)\n",
    "            # time stretch\n",
    "            tr = 2.0 #speed up/down rate\n",
    "            lgtr = np.log(tr)\n",
    "            ts = 2 ** np.random.uniform(-lgtr,lgtr)\n",
    "            shifted_data = librosa.effects.time_stretch(shifted_data, ts)\n",
    "            # white noise\n",
    "            wnvr = 0.05 # white noise volume range\n",
    "            wnv  = np.random.uniform(0, wnvr) # white noise volume, random\n",
    "            shifted_data += np.random.uniform(-wnv, wnv, shifted_data.shape)\n",
    "            # Random offset / Padding\n",
    "            if len(shifted_data) > input_length:\n",
    "                max_offset = len(shifted_data) - input_length\n",
    "                offset = np.random.randint(max_offset)\n",
    "                shifted_data = shifted_data[offset:(input_length+offset)]\n",
    "            else:\n",
    "                if input_length > len(shifted_data):\n",
    "                    max_offset = input_length - len(shifted_data)\n",
    "                    offset = np.random.randint(max_offset)\n",
    "                else:\n",
    "                    offset = 0\n",
    "                shifted_data = np.pad(shifted_data, (offset, input_length - len(shifted_data) - offset), \"constant\")\n",
    "            #mfcc\n",
    "            shifted_data = librosa.feature.mfcc(shifted_data, sr=config.sampling_rate, n_mfcc=config.n_mfcc)\n",
    "            shifted_data = np.expand_dims(shifted_data, axis=-1)\n",
    "            X[ i * config.datagen_num + j, :] = shifted_data\n",
    "            y[ i * config.datagen_num + j] = df.label_idx[i]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data(data_dir):\n",
    "    df = pd.read_csv('../input/test.csv')\n",
    "    for fname in df['fname']:\n",
    "        print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(sampling_rate=44100, audio_duration=2, n_folds=5, \n",
    "                learning_rate=0.001, use_mfcc=True, n_mfcc=40, datagen_num=2)\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "LABELS = list(train.label.unique())\n",
    "label_idx = {label: i for i, label in enumerate(LABELS)}\n",
    "train.set_index(\"fname\", inplace=True)\n",
    "train[\"label_idx\"] = train.label.apply(lambda x: label_idx[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00044347.wav\n",
      "001ca53d.wav\n",
      "002d256b.wav\n",
      "0033e230.wav\n",
      "00353774.wav\n",
      "003b91e8.wav\n",
      "003da8e5.wav\n",
      "0048fd00.wav\n",
      "004ad66f.wav\n",
      "0063ab88.wav\n",
      "006f2f32.wav\n",
      "0075d39c.wav\n",
      "00780200.wav\n",
      "0079d310.wav\n",
      "0091fc7f.wav\n",
      "0097160c.wav\n",
      "00ad7068.wav\n",
      "00c5808a.wav\n",
      "00c82919.wav\n",
      "00c934d7.wav\n",
      "00c9e799.wav\n",
      "00cb787c.wav\n",
      "00ce569f.wav\n",
      "00d1fe46.wav\n",
      "00d3bba3.wav\n",
      "00d40fa2.wav\n",
      "00d9fa61.wav\n",
      "00e2b4cd.wav\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3006bd54df56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'../input/audio_train/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-2302a93c7d93>\u001b[0m in \u001b[0;36mprepare_data\u001b[1;34m(df, config, data_dir)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mlgtr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlgtr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlgtr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mshifted_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_stretch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshifted_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[1;31m# white noise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mwnvr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m \u001b[1;31m# white noise volume range\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\librosa\\effects.py\u001b[0m in \u001b[0;36mtime_stretch\u001b[1;34m(y, rate)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;31m# Construct the stft\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m     \u001b[0mstft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;31m# Stretch by phase vocoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\librosa\\core\\spectrum.py\u001b[0m in \u001b[0;36mstft\u001b[1;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;31m# RFFT and Conjugate here to match phase from DPWE code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         stft_matrix[:, bl_s:bl_t] = fft.fft(fft_window *\n\u001b[1;32m--> 183\u001b[1;33m                                             \u001b[0my_frames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbl_s\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbl_t\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m                                             axis=0)[:stft_matrix.shape[0]]\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, y = prepare_data(train, config, '../input/audio_train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train.npy',X_train)\n",
    "np.save('y.npy',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00063640.wav\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-a1e1d84aa22f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0moffset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_length\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mmfcc_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_mfcc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mmfcc_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfcc_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\numpy\\lib\\arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[1;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[0;32m   1368\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_before\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad_after\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbefore_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mafter_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m                 \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'constant_values'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m             \u001b[0mnewmat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_prepend_const\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad_before\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbefore_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m             \u001b[0mnewmat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_append_const\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad_after\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mafter_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\numpy\\lib\\arraypad.py\u001b[0m in \u001b[0;36m_prepend_const\u001b[1;34m(arr, pad_amt, val, axis)\u001b[0m\n\u001b[0;32m    102\u001b[0m                      for (i, x) in enumerate(arr.shape))\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         return np.concatenate((np.zeros(padshape, dtype=arr.dtype), arr),\n\u001b[0m\u001b[0;32m    105\u001b[0m                               axis=axis)\n\u001b[0;32m    106\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_dir = '../input/audio_test/'\n",
    "test_data = np.empty(shape=(df.shape[0], config.dim[0], config.dim[1], 1))\n",
    "input_length = config.audio_length\n",
    "for i, fname in enumerate(df['fname']):\n",
    "    print(fname)\n",
    "    file_path = data_dir + fname\n",
    "    data, _ = librosa.core.load(file_path, sr=config.sampling_rate)\n",
    "    data = audio_norm(data)\n",
    "    # Random offset / Padding\n",
    "    if len(test_data) > input_length:\n",
    "        max_offset = len(test_data) - input_length\n",
    "        offset = np.random.randint(max_offset)\n",
    "        test_data = test_data[offset:(input_length+offset)]\n",
    "    else:\n",
    "        if input_length > len(test_data):\n",
    "            max_offset = input_length - len(test_data)\n",
    "            offset = np.random.randint(max_offset)\n",
    "        else:\n",
    "            offset = 0\n",
    "        test_data = np.pad(test_data, (offset, input_length - len(test_data) - offset), \"constant\")\n",
    "    mfcc_data = librosa.feature.mfcc(data, sr=config.sampling_rate, n_mfcc=config.n_mfcc)\n",
    "    mfcc_data = np.expand_dims(mfcc_data, axis=-1)\n",
    "    test_data[i] = mfcc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.dim[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.dim[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
